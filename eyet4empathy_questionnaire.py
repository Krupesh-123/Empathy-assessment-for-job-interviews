# -*- coding: utf-8 -*-
"""Eyet4empathy questionnaire.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jVarAPrvzFc5x5KuW6Cl8FsA-IGknXNs
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd 
import numpy as np
import seaborn as sns 
import matplotlib.pyplot as plt 
# %matplotlib inline 
sns.set_theme()
import warnings
warnings.filterwarnings('ignore')

#using latin encoding because utf-8 and utf-16 cannot recognise unidentified characters in the data and so are unable to load the data.
df0 = pd.read_csv('Questionnaire_datasetIA.csv', encoding = 'latin-1' )
df1 = pd.read_csv('Questionnaire_datasetIB.csv', encoding = 'latin-1')

df0.head(5)

df1.head(5)

"""df0 and df1 as seen above have the same features with same datatypes but 
different values so it logical to use one dataset as a train set and the other as a test set. This will also ensure the variance of the data and prevent overfitting. 
"""

print(df0.info())

print(df1.info())

"""taking df0, the questionnaire answered before the gaze experiments as the train set.

#    EDA
"""

#checking for null values
plt.figure(figsize=(4,2))
sns.heatmap(df0.isnull(), cbar = False)
#no null values

"""The following features will be dropped.

---
Participant nr - It is an index and will not be of any use for predictions.

NR - Some random numbers. 

Created and Modified have the same values and represent the timestamp of when the data files were created and modified. Created will be dropped and modified will be engineered to extract the time specifically which potentially is useful to the assessment. 

The elapsed time will be converted to seconds (int).
"""

df0.drop(['Participant nr', 'NR', 'Created'], axis = 1, inplace = True)

df0['I have read and understood the information about the study and all the information in this form is explained to me and I am willing to participate'].unique()

"""This row has all values the same and will not be of use to the assessment."""

df0.drop('I have read and understood the information about the study and all the information in this form is explained to me and I am willing to participate', axis = 1, inplace = True)

df0['I want to participate.'].unique()

"""All values here are also the same and will not be of positive to the model's assessment, it is logical to drop them. """

df0.drop('I want to participate.', axis = 1, inplace = True)

#extracting the HH:MM of the full timestamp
df0['Modified']= (pd.to_datetime(df0['Modified'])).dt.strftime('%H:%M')
df0['Modified'][0:4]

#converting the elapsed time to seconds
def sec_calc(time):
    time = time.split(' ')
    sec_time = int(time[0])*60 + int(time[2])
    return sec_time 
df0['Elapsed'] = df0['Elapsed time'].apply(sec_calc)
df0.drop('Elapsed time', axis = 1, inplace = True)
df1['Elapsed'] = df1['Elapsed time'].apply(sec_calc)
df1.drop('Elapsed time', axis = 1, inplace = True)

df0.head(5)

#checking the correlatio
plt.figure(figsize= (4,2))
sns.heatmap(df0.iloc[:, 41:].corr(), annot = True)

"""The correlation between time elapsed and the total score original is very low and that between time elapsed and total score extended way lower, keeping it for training could be more detrimental than beneficial.

The rest of the features are numerical and range from 1 to 4.The empathy scores are based on assessment of this responses.
The total score extended seems to be proportional with the time elapsed.  
There are many features and exploring each one at a time to find the correlation with the target would be time consuming so feature selection will be performed.

FEATURE SELECTION USING FILTER METHOD (SUPERVISED TECHNIQUE)
"""

X = df0.drop(['Total Score original','Total Score extended', 'Modified'], axis = 1)
y_train = df0['Total Score original']

"""FEATURE SELECTION USING MUTUAL INFORMATION REGRESSOR"""

from sklearn. feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
# Using anova function to select the 15 best features
selector =SelectKBest(f_classif, k=15)
X_reduced = selector.fit_transform(X, y_train)
X_reduced.shape

X_reduced

cols = selector.get_feature_names_out()
cols

#Visualizing the new feature data
X_train = pd.DataFrame(X_reduced, columns= cols)
X_train.head(5)

"""## Feature Selection for the test set data (df1)

The features selected in the training dataset are already nominal so there would not be need for any engineering on the test set.
"""

y_test = df1['Total Score original']
X_test = df1[cols]
X_test.head(5)

#model selection and initialization 
from sklearn.metrics import mean_absolute_error, mean_squared_error,explained_variance_score
from sklearn.linear_model import SGDRegressor
sgd = SGDRegressor(max_iter=20000,
                     tol=1e-3,
                     learning_rate='invscaling',
                     n_iter_no_change=6,
                     random_state=32)
#fitting the model to the training data
sgd.fit(X_train,y_train)
#predicting the empathy scores on the test set
y_pred = np.rint(sgd.predict(X_test))
#evaluating the model 
print('MAE: ', mean_absolute_error(y_test, y_pred))
print('RMSE: ',mean_squared_error(y_test, y_pred, squared= False))
print('Explained Variance Score:',explained_variance_score(y_test, y_pred))

# trained for before stopping
coef = dict(zip(X_train.columns, sgd.coef_.T))
print('Feature Coefficients:',coef)
print('Number of Iterations:',sgd.n_iter_)

#visualizing the model's prediction accuracy 
#creating a scatterplot of the values
plt.scatter(y_test,y_pred,cmap = 'viridis')
#drawing a line of best fit
plt.plot (np.unique (y_test), np.poly1d (np.polyfit (y_test,y_pred, 1))(np.unique (y_test)), color = 'green') 
#adding titles and labels 
plt.title('SGDRegressor Accuracy')
plt.xlabel('Original Empathy Scores')
plt.ylabel('Predicted Empathy Scores')
plt.show()